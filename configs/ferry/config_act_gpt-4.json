{
    "llm_config": {
        "plan": {
            "model_name": "openai_chat",
            "model_path": "gpt-4",
            "examples_chat": false,
            "prompt_file": "./llm_planning/prompt_templates/planning_template_interactive.txt",
            "temp": 0,
            "max_tokens": null,
            "max_history": null
        },
        "translate": {
            "model_name": "openai_chat",
            "model_path": "gpt-4",
            "examples_chat": false,
            "prompt_file": "./llm_planning/prompt_templates/translation_template.txt",
            "examples_file": "/local/kstein/autoplanbench/data/ferry/translation_examples.json",
            "temp": 0,
            "max_tokens": 256,
            "max_history": 0
        }
    },
    "task_nums": [
        16,
        25,
        18,
        23,
        20,
        10,
        11,
        24,
        17,
        15,
        9,
        21,
        7,
        13,
        8,
        6,
        4,
        12,
        19,
        5
    ],
    "domain_dir": "/local/kstein/autoplanbench/data/ferry",
    "domain_file": "/local/kstein/autoplanbench/data/ferry/domain.pddl",
    "domain_nl_file": "/local/kstein/autoplanbench/data/ferry/domain_description.json",
    "instance_dir": "/local/kstein/autoplanbench/data/ferry/adapted_instances",
    "planning_approach": "act",
    "encoding_type": "automatic",
    "translation_neural": true,
    "incremental": true,
    "thoughts": false,
    "positive_feedback": "full",
    "negative_feedback": "full",
    "subgoal_feedback": false,
    "provide_state": false,
    "not_finished_feedback": true,
    "log_history": false,
    "run_config": {
        "steps": 24,
        "break_limit": 5,
        "directory": "ferry_act_1_shot"
    }
}