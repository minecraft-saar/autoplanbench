## Dataset and Experiments 

### 1 Overview
See the [readme](https://github.com/minecraft-saar/autoplanbench/blob/main/data_main/readme.md) of the data repository for information about how to extract the data.

The dataset folder contains all the files of the 12 domains used in the experiments as well as the configuration files that were used to run them:

**Configuration files**:
* configs_main: configurations for the main experiments
* configs_pddl: configurations for the PDDL experiments
* configs_planbench: configurations for the experiments on the NL descriptions from Valmeekam et al.
* configs_scaled: configurations for the experiments on the scaled dataset <br>

In order to run the same experiments, the absolute paths in the configuration files need to be replace (i.e. replace '/local/kstein' with the adquate path)

**Few-shot example instances used:**
* few_shot_ids.json: lists for each of the domains the ID of the instance from the data_main(!) dataset that was used as few-shot example in our experiments; 

**Datasets**:
* data_main: contains all files for the main dataset
* data_planbench: contains all files for running the LLM planning on the manual descriptions from Valmeekam et al.
* data_scaled: contains all files for the scaled dataset

For the contents of the dataset folders and the format of the few-shot example files see below

### 2 Dataset Subfolders

The dataset folders contain the data of the 12 domains that were used in the experiments. (Note, the StateReasoning approach was actually not used).

Each subfolder contains the following data:

* **domain.pddl**: the domain definition in PDDL
* **domain_description.json**: the natural language descriptions of the domain generated by AutoPlanBench
* **instance_object_mappings.json**: the mappings between object names in the original problems generated by the problem generators and the object names in the adapted problem files that are used for the LLM planning
* **translation_examples.json**: domain-specific few-shot examples for the T-LLM, i.e. for translating the actions predicted in natural language back to PDDL
* **translation_examples_dict.json**: a second version for domain-specific few-shot examples for the T-LLM; this version can be used e.g. if there are object names in the natural language descriptions that are not valid object names in PDDL (e.g. if using multi-token names). Then the translation is done in two steps. Note that these files have not been actually used in the experiments


* **adapted_instances**: the problems selected from the problems in orig_problems given the constraints that they are 1) solvable and 2) their gold plans consist of 2 - 20 steps; problems differ from the orig_problems only w.r.t. their names
* **few_shot_examples_act**: few-shot examples for the Act planning approach on NL input
* **few_shot_examples_act_pddl**: few-shot examples for the Act planning approach on PDDL input
* **few_shot_examples_basic**: few-shot examples for the Basic planning approach on NL input
* **few_shot_examples_basic_pddl**: few-shot examples for the Basic planning approach on PDDL input
* **few_shot_examples_cot**: 
    * cot_example_instance-X.json: the CoT example based on instance-X, obtained by removing the observations from the react_example_instance-X.json on NL input
* **few_shot_examples_react**: 
    * react_template_instance-X.json: the template for a react example based on instance-X without the thoughts
    * react_example_instance-X.json: the React example based on instance-X with thoughts
    * **Note**: instance-0 means that the problem was designed manually
    * on NL input
* **few_shot_examples_state_reasoning**: few-shot examples for the StateReasoning planning approach on NL input (were not used for the paper)
* **gold_plans**: optimal gold plans generated using A* search and lmcut for all problems in adapted_instances and in not_selected_by_filter (if solvable)
* **not_selected_by_filter**: contains all problems that were filtered out from the adapted_instances because 1) they are not solvable, 2) do not match the length constraint or 3) are left over after having selected 21 problems
* **orig_problems**: the original problems generated by the problem generators

### 3 data_planbench folder

The folder data_planbench contains all data from the experiments based on the domain descriptions created by [Valmeekam et al.](https://github.com/karthikv792/LLMs-Planning/tree/main/plan-bench). 

The **.yaml** files are the original configuration files from their repository. The original problems (i.e. before adapting the object names) for the blocksworld and logistics domain were taken from their repository as well and are not included in our data set. The **domain_description.json** files are created based on the 'intro' and 'mappings' in the original .yaml files.

The rest of the files and folders is the same as described above. 

### 4 manual_react_examples

The folder contains the manually created React and CoT examples from the blocksworld and logistics domain. These are the same files as the react/cot_example_instance-0.json files in the data and data_planbench subfolders. 

The manually created logistics example can also be found in [here](https://github.com/minecraft-saar/autoplanbench/tree/main/llm_planning/manual_react_examples)

### 5 Format of the few-shot examples

The overall structure for the few-shot examples looks like this:
```
{
    "prefixes": {
        "input": "",
        "output": "",
    },
    "pos_examples": 
    [
        [example1_input,
        example1_output],
        [example2_input,
        example2_output],
        ...
    ]
}
```
"prefixes" are the prefixes that get attached at the beginning of each input and output respectively when presenting the examples to the model. When using an interactive planning approach this is always set to "", i.e. no prefixes are added.

"pos_examples" is a list of all few-shot examples, where each example is a 2-element list where the first element is the input and the second the output. For interactive planning approaches the output is usually set to "" because each examples presents a complete interaction by itself.
